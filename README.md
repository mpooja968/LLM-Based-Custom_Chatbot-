# LLM-Based-Custom_Chatbot-
CPU-optimized chatbot using LLama 3 with RAG and fine-tuned Alpaca models. Built on Intel Extension for Transformers, with Streamlit UI, PDF upload, and contextual domain-specific responses.

This project implements a CPU-efficient chatbot system leveraging the power of **LLama 3**, deployed with two state-of-the-art approaches: **Retrieval-Augmented Generation (RAG)** and **Fine-Tuning using the Alpaca dataset**. The solution was built as part of the **Intel Unnati Industrial Training Program** and is optimized using **Intel Extension for Transformers** to enable efficient performance on Intel CPU architectures without the need for GPUs.

It supports **PDF ingestion**, **contextual question answering**, and real-time conversational responses through an intuitive **Streamlit interface**, designed to support research and domain-specific querying.

